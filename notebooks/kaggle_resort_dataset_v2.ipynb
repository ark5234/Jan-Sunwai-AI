{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b482370d",
   "metadata": {},
   "source": [
    "# Jan-Sunwai AI â€” Dataset Re-Sorter v2 (Kaggle Edition)\n",
    "\n",
    "Re-sorts the civic complaint image dataset using the **improved two-step Ollama AI pipeline** with all fixes:\n",
    "\n",
    "### What's new in v2\n",
    "| Fix | Description |\n",
    "|-----|-------------|\n",
    "| **New models** | `llama3.2-vision:11b` (vision) + `mistral:7b` (reasoning) â€” stronger than qwen2.5vl + llama3.1 |\n",
    "| `format=\"json\"` | Forces structured JSON output from Ollama â€” eliminates string matching failures |\n",
    "| Hierarchical prompts | Groups â†’ Departments â€” makes classification easier for the model |\n",
    "| Keyword fallback | Scans vision description for civic keywords when reasoning returns Uncategorized |\n",
    "| Real confidence | Uses model-reported confidence (0.0â€“1.0) instead of hardcoded values |\n",
    "| Full audit trail | Logs method used, rationale, raw JSON for every image â€” full explainability |\n",
    "\n",
    "### Models (Kaggle GPU â€” 16 GB VRAM)\n",
    "| Step | Model | Size | Role |\n",
    "|------|-------|------|------|\n",
    "| Vision | `llama3.2-vision:11b` | ~6.7 GB | Meta's latest multimodal â€” superior visual understanding |\n",
    "| Reasoning | `mistral:7b` | ~4.1 GB | Excellent at structured JSON output & instruction following |\n",
    "\n",
    "Both models run sequentially (~10.8 GB peak VRAM), fits within 16 GB.\n",
    "\n",
    "### Fast mode\n",
    "Single-pass with `llama3.2-vision:11b` + `format=\"json\"` â€” faster but slightly less accurate.\n",
    "\n",
    "## Before running\n",
    "1. The dataset has been split into **5 parts** (`backend/sorted_dataset_parts/part1` â€¦ `part5`).  \n",
    "   Each part contains **all departments** with a random ~â…• of each department's images (~1 GB per part).\n",
    "2. Zip and upload each part as a separate Kaggle Dataset:\n",
    "   - Kaggle â†’ Datasets â†’ New Dataset â†’ upload `part1.zip` â†’ name it e.g. `jan-sunwai-part1`\n",
    "   - Repeat for `part2` â€¦ `part5`\n",
    "3. Add all 5 datasets to this notebook: **Add Data â†’ Your Datasets â†’ select each one**\n",
    "4. Update `PART_ROOTS` in Section 2 to match your dataset slugs if different\n",
    "5. Enable **GPU accelerator**: **GPU P100** (recommended) or **GPU T4 x1**\n",
    "6. Enable **Internet access** (Settings â†’ Internet â†’ On)\n",
    "7. **Restart kernel** before running to avoid stale variables\n",
    "8. Run All\n",
    "\n",
    "## Output\n",
    "- `/kaggle/working/ai_resort_report_v2.csv` â€” full classification audit trail\n",
    "- `/kaggle/working/ai_sorted_dataset/<Category>/` â€” correctly sorted images"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b71ab365",
   "metadata": {},
   "source": [
    "## 1 â€” Install Ollama and start server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "441dd42c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess, time, os\n",
    "\n",
    "# Install pciutils (lspci) + zstd â€” both required before Ollama install\n",
    "print('Installing pciutils + zstd...')\n",
    "subprocess.run(['apt-get', 'install', '-y', 'pciutils', 'zstd'],\n",
    "               check=True, capture_output=True)\n",
    "print('Done.')\n",
    "\n",
    "# Verify GPU is visible\n",
    "print('\\n--- GPU check (lspci) ---')\n",
    "r = subprocess.run(['lspci'], capture_output=True, text=True)\n",
    "gpu_lines = [l for l in r.stdout.splitlines() if 'NVIDIA' in l or 'VGA' in l or '3D' in l]\n",
    "for l in gpu_lines:\n",
    "    print(' ', l)\n",
    "if not gpu_lines:\n",
    "    print('  âš  No GPU found via lspci â€” check accelerator settings')\n",
    "\n",
    "# Install Ollama\n",
    "print('\\nInstalling Ollama...')\n",
    "result = subprocess.run('curl -fsSL https://ollama.com/install.sh | sh',\n",
    "                        shell=True, capture_output=True, text=True)\n",
    "print(result.stdout[-600:] if result.stdout else 'done')\n",
    "if result.returncode != 0:\n",
    "    print('STDERR:', result.stderr[-300:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9f68e39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confirm CUDA GPU is available\n",
    "print('--- nvidia-smi ---')\n",
    "r = subprocess.run(['nvidia-smi', '--query-gpu=name,memory.total,driver_version',\n",
    "                    '--format=csv,noheader'], capture_output=True, text=True)\n",
    "if r.returncode == 0:\n",
    "    print(r.stdout.strip())\n",
    "else:\n",
    "    print('nvidia-smi not found â€” models will run on CPU (much slower).')\n",
    "\n",
    "# Start Ollama server with GPU env vars\n",
    "gpu_env = {\n",
    "    **os.environ,\n",
    "    'OLLAMA_NUM_GPU': '999',\n",
    "    'CUDA_VISIBLE_DEVICES': '0',\n",
    "}\n",
    "server = subprocess.Popen(['ollama', 'serve'],\n",
    "                          stdout=subprocess.DEVNULL,\n",
    "                          stderr=subprocess.DEVNULL,\n",
    "                          env=gpu_env)\n",
    "print(f'\\nOllama server PID: {server.pid}')\n",
    "time.sleep(5)\n",
    "\n",
    "r = subprocess.run(['ollama', 'list'], capture_output=True, text=True)\n",
    "print(r.stdout or 'Server ready')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a4f4768",
   "metadata": {},
   "outputs": [],
   "source": [
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# MODE SELECTOR â€” choose 'fast' or 'accuracy'\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "#   fast:     single-pass llama3.2-vision:11b with format='json'\n",
    "#             ~3-4 s/img, good accuracy with JSON enforcement\n",
    "#   accuracy: two-step llama3.2-vision:11b â†’ mistral:7b with format='json'\n",
    "#             ~6-8 s/img, best accuracy with hierarchical classification\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "MODE = 'accuracy'   # <--- CHANGE THIS\n",
    "\n",
    "if MODE == 'fast':\n",
    "    VISION_MODEL    = 'llama3.2-vision:11b'   # single-pass with Meta's latest\n",
    "    REASONING_MODEL = None\n",
    "    SINGLE_PASS     = True\n",
    "    EST_SECONDS     = 3.5\n",
    "else:\n",
    "    VISION_MODEL    = 'llama3.2-vision:11b'   # Meta's latest multimodal\n",
    "    REASONING_MODEL = 'mistral:7b'             # excellent at structured JSON\n",
    "    SINGLE_PASS     = False\n",
    "    EST_SECONDS     = 7.0\n",
    "\n",
    "print(f'MODE       = {MODE}')\n",
    "print(f'Vision     = {VISION_MODEL}')\n",
    "print(f'Reasoning  = {REASONING_MODEL or \"(single-pass)\"}')\n",
    "\n",
    "print(f'\\nPulling {VISION_MODEL}...')\n",
    "subprocess.run(['ollama', 'pull', VISION_MODEL], check=True)\n",
    "\n",
    "if REASONING_MODEL:\n",
    "    print(f'\\nPulling {REASONING_MODEL}...')\n",
    "    subprocess.run(['ollama', 'pull', REASONING_MODEL], check=True)\n",
    "\n",
    "print('\\nLoaded models:')\n",
    "subprocess.run(['ollama', 'list'])\n",
    "\n",
    "# Quick GPU residency check\n",
    "print('\\n--- GPU VRAM usage ---')\n",
    "r = subprocess.run(['nvidia-smi', '--query-compute-apps=pid,used_gpu_memory',\n",
    "                    '--format=csv,noheader'], capture_output=True, text=True)\n",
    "print(r.stdout.strip() if r.returncode == 0 else '(cannot query GPU processes)')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9879a40",
   "metadata": {},
   "source": [
    "## 2 â€” Load dataset (multi-part Kaggle input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "787bf3d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "IMAGE_EXTS = {'.jpg', '.jpeg', '.png', '.webp', '.bmp', '.tiff'}\n",
    "\n",
    "# â”€â”€ Multi-part dataset support â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "# Update slugs to match your actual Kaggle dataset names\n",
    "PART_ROOTS = [Path(f'/kaggle/input/jan-sunwai-part{i}') for i in range(1, 6)]\n",
    "\n",
    "INPUT_ROOTS = [p for p in PART_ROOTS if p.exists()]\n",
    "\n",
    "if not INPUT_ROOTS:\n",
    "    print('âš   None of the expected dataset paths found. Available inputs:')\n",
    "    for p in sorted(Path('/kaggle/input').iterdir()):\n",
    "        print(' ', p)\n",
    "    raise FileNotFoundError('No dataset parts found. Attach them and update PART_ROOTS.')\n",
    "\n",
    "print(f'Found {len(INPUT_ROOTS)} / {len(PART_ROOTS)} dataset parts.')\n",
    "\n",
    "OUTPUT_ROOT = Path('/kaggle/working/ai_sorted_dataset')\n",
    "REPORT_CSV  = Path('/kaggle/working/ai_resort_report_v2.csv')\n",
    "AUDIT_JSON  = Path('/kaggle/working/ai_audit_trail.json')\n",
    "\n",
    "print(f'Output : {OUTPUT_ROOT}')\n",
    "print(f'Report : {REPORT_CSV}')\n",
    "\n",
    "# Count images per category across all parts\n",
    "cat_counts: dict[str, int] = {}\n",
    "total = 0\n",
    "for root in INPUT_ROOTS:\n",
    "    for folder in sorted(root.iterdir()):\n",
    "        if folder.is_dir():\n",
    "            n = len([p for p in folder.iterdir() if p.suffix.lower() in IMAGE_EXTS])\n",
    "            cat_counts[folder.name] = cat_counts.get(folder.name, 0) + n\n",
    "            total += n\n",
    "\n",
    "for cat, n in sorted(cat_counts.items()):\n",
    "    print(f'  {cat:<45} {n:>5} images')\n",
    "\n",
    "print(f'\\nTotal : {total} images across {len(INPUT_ROOTS)} parts')\n",
    "print(f'Est.  : ~{total * EST_SECONDS / 3600:.1f} h at ~{EST_SECONDS:.1f} s/img')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5a38112",
   "metadata": {},
   "source": [
    "## 3 â€” Classifier (self-contained, all fixes included)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77fb5ced",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install Python dependencies\n",
    "subprocess.run(['pip', 'install', '-q', '--upgrade', 'ollama', 'pillow'], check=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a211418",
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "import json\n",
    "import ollama\n",
    "from PIL import Image\n",
    "\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# CANONICAL CATEGORIES (11 civic complaint departments)\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "CANONICAL_CATEGORIES = [\n",
    "    'Municipal - PWD (Roads)',\n",
    "    'Municipal - Sanitation',\n",
    "    'Municipal - Horticulture',\n",
    "    'Municipal - Street Lighting',\n",
    "    'Municipal - Water & Sewerage',\n",
    "    'Utility - Power (DISCOM)',\n",
    "    'State Transport',\n",
    "    'Pollution Control Board',\n",
    "    'Police - Local Law Enforcement',\n",
    "    'Police - Traffic',\n",
    "    'Uncategorized',\n",
    "]\n",
    "\n",
    "CATEGORY_DEFINITIONS = {\n",
    "    'Municipal - PWD (Roads)':        'broken roads, potholes, cracked pavement, damaged footpaths, bridge damage',\n",
    "    'Municipal - Sanitation':         'garbage dumps, overflowing trash bins, dirty public toilets, waste piles on streets',\n",
    "    'Municipal - Horticulture':       'fallen or uprooted trees, overgrown vegetation, unmaintained parks, dead/dry plants',\n",
    "    'Municipal - Street Lighting':    'broken street lights, non-functional lamp posts, dark or unlit public roads',\n",
    "    'Municipal - Water & Sewerage':   'waterlogging, flooded streets, blocked drains, sewer overflow, water pipe leaks',\n",
    "    'Utility - Power (DISCOM)':       'dangling electrical wires, open or damaged transformers, hazardous power cables',\n",
    "    'State Transport':                'damaged bus shelters, broken state buses, transport terminal damage',\n",
    "    'Pollution Control Board':        'air pollution, thick smoke, industrial waste dumping, open burning of garbage',\n",
    "    'Police - Local Law Enforcement': 'illegal parking, footpath encroachment, public nuisance, fights or brawls',\n",
    "    'Police - Traffic':               'failed traffic signals, road blockages, severe traffic congestion',\n",
    "    'Uncategorized':                  'does not clearly match any of the above civic categories',\n",
    "}\n",
    "\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# ALIAS MAP â€” normalises model output to canonical names\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "_ALIAS_MAP = {\n",
    "    'municipal - pwd (roads)':         'Municipal - PWD (Roads)',\n",
    "    'municipal - pwd roads':           'Municipal - PWD (Roads)',\n",
    "    'municipal - sanitation':          'Municipal - Sanitation',\n",
    "    'municipal - horticulture':        'Municipal - Horticulture',\n",
    "    'municipal - street lighting':     'Municipal - Street Lighting',\n",
    "    'municipal - water & sewerage':    'Municipal - Water & Sewerage',\n",
    "    'municipal - water and sewerage':  'Municipal - Water & Sewerage',\n",
    "    'utility - power (discom)':        'Utility - Power (DISCOM)',\n",
    "    'utility - power discom':          'Utility - Power (DISCOM)',\n",
    "    'state transport':                 'State Transport',\n",
    "    'pollution control board':         'Pollution Control Board',\n",
    "    'police - local law enforcement':  'Police - Local Law Enforcement',\n",
    "    'police - traffic':                'Police - Traffic',\n",
    "    'uncategorized':                   'Uncategorized',\n",
    "}\n",
    "\n",
    "def canonicalize(label: str) -> str:\n",
    "    \"\"\"Map model output to canonical category. Handles partial / fuzzy matches.\"\"\"\n",
    "    cleaned = label.strip().lower()\n",
    "    if cleaned in _ALIAS_MAP:\n",
    "        return _ALIAS_MAP[cleaned]\n",
    "    # Fuzzy: check if any alias is a substring or vice versa\n",
    "    for alias, canonical in _ALIAS_MAP.items():\n",
    "        if cleaned in alias or alias in cleaned:\n",
    "            return canonical\n",
    "    return 'Uncategorized'\n",
    "\n",
    "\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# FIX 1: KEYWORD FALLBACK â€” catches what reasoning model misses\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "_KEYWORD_FALLBACK = [\n",
    "    (['pothole', 'road damage', 'cracked road', 'broken road', 'damaged road',\n",
    "      'damaged pavement', 'broken pavement', 'footpath damage', 'manhole'],\n",
    "     'Municipal - PWD (Roads)'),\n",
    "    (['waterlog', 'flooded', 'flood', 'drain overflow', 'sewer overflow',\n",
    "      'pipe leak', 'water gushing', 'stagnant water', 'blocked drain',\n",
    "      'drainage problem'],\n",
    "     'Municipal - Water & Sewerage'),\n",
    "    (['garbage', 'trash', 'waste', 'litter', 'dump', 'rubbish', 'overflowing bin'],\n",
    "     'Municipal - Sanitation'),\n",
    "    (['fallen tree', 'uprooted tree', 'overgrown', 'dead plant', 'broken branch',\n",
    "      'tree blocking'],\n",
    "     'Municipal - Horticulture'),\n",
    "    (['street light', 'lamp post', 'unlit road', 'broken light', 'dark road'],\n",
    "     'Municipal - Street Lighting'),\n",
    "    (['dangling wire', 'hanging wire', 'open transformer', 'fallen electric pole',\n",
    "      'exposed wire', 'power cable'],\n",
    "     'Utility - Power (DISCOM)'),\n",
    "    (['smoke', 'burning', 'industrial waste', 'air pollution', 'open burning'],\n",
    "     'Pollution Control Board'),\n",
    "    (['traffic signal', 'signal failure', 'traffic jam', 'road blockage'],\n",
    "     'Police - Traffic'),\n",
    "    (['illegal parking', 'encroachment', 'footpath blocked', 'public nuisance'],\n",
    "     'Police - Local Law Enforcement'),\n",
    "    (['bus shelter', 'state bus', 'transport terminal'],\n",
    "     'State Transport'),\n",
    "]\n",
    "\n",
    "_NEGATIVE_KEYWORDS = [\n",
    "    'selfie', 'portrait', 'food', 'meal', 'restaurant', 'cartoon', 'anime',\n",
    "    'gaming', 'screenshot', 'indoor furniture', 'appliance', 'pet', 'animal',\n",
    "    'beautiful landscape', 'clear sky',\n",
    "]\n",
    "\n",
    "def keyword_fallback(description: str) -> str:\n",
    "    \"\"\"Scan vision description for civic keywords â†’ best matching category.\"\"\"\n",
    "    desc = description.lower()\n",
    "    for keywords, category in _KEYWORD_FALLBACK:\n",
    "        if any(kw in desc for kw in keywords):\n",
    "            return category\n",
    "    return 'Uncategorized'\n",
    "\n",
    "\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# HELPER FUNCTIONS\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "def safe_dirname(label: str) -> str:\n",
    "    return label.replace(' ', '_').replace('(', '').replace(')', '').replace('&', 'and')\n",
    "\n",
    "def load_as_jpeg_bytes(path: Path) -> bytes:\n",
    "    with Image.open(path) as img:\n",
    "        if img.mode != 'RGB':\n",
    "            img = img.convert('RGB')\n",
    "        buf = io.BytesIO()\n",
    "        img.save(buf, format='JPEG', quality=85)\n",
    "        return buf.getvalue()\n",
    "\n",
    "\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# FIX 2: HIERARCHICAL CLASSIFICATION PROMPT (for reasoning step)\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "def _build_reasoning_prompt(description: str) -> str:\n",
    "    \"\"\"Hierarchical prompt: first identify group, then specific department.\"\"\"\n",
    "    categories_block = '\\n'.join(\n",
    "        f'- {cat}: {CATEGORY_DEFINITIONS[cat]}' for cat in CANONICAL_CATEGORIES\n",
    "    )\n",
    "    return (\n",
    "        f'You are a civic complaint classifier for Indian municipal authorities.\\n\\n'\n",
    "        f'Image description: \"{description}\"\\n\\n'\n",
    "        f'First determine the department GROUP, then the specific department.\\n\\n'\n",
    "        f'Groups:\\n'\n",
    "        f'- Municipal: city infrastructure (roads, sanitation, horticulture, lighting, water/sewerage)\\n'\n",
    "        f'- Police: law enforcement and traffic management\\n'\n",
    "        f'- Utility: electrical power distribution (wires, transformers)\\n'\n",
    "        f'- State Transport: public bus/transport infrastructure\\n'\n",
    "        f'- Pollution Control Board: air/water/soil pollution\\n'\n",
    "        f'- Uncategorized: no civic issue visible or unrecognisable image\\n\\n'\n",
    "        f'Specific categories:\\n'\n",
    "        f'{categories_block}\\n\\n'\n",
    "        f'Decision rules:\\n'\n",
    "        f'1. Dangling wires, power cables, transformer, electric pole â†’ Utility - Power (DISCOM)\\n'\n",
    "        f'2. Waterlogging, flood, drain overflow, sewer, pipe leak â†’ Municipal - Water & Sewerage\\n'\n",
    "        f'3. Garbage, trash, waste, dump, litter, bins â†’ Municipal - Sanitation\\n'\n",
    "        f'4. Potholes, road cracks, broken road, pavement damage â†’ Municipal - PWD (Roads)\\n'\n",
    "        f'5. Broken street lights, lamp posts, unlit road â†’ Municipal - Street Lighting\\n'\n",
    "        f'6. Fallen trees, overgrown parks, dead plants â†’ Municipal - Horticulture\\n'\n",
    "        f'7. Smoke, burning, industrial pollution â†’ Pollution Control Board\\n'\n",
    "        f'8. Illegal parking, encroachment â†’ Police - Local Law Enforcement\\n'\n",
    "        f'9. Traffic signal failure, road blockage â†’ Police - Traffic\\n'\n",
    "        f'10. Damaged bus shelter, state bus â†’ State Transport\\n'\n",
    "        f'11. Black/blurry/selfie/food â†’ Uncategorized\\n\\n'\n",
    "        f'Do NOT default to Water & Sewerage unless water/flooding/drain is explicit.\\n'\n",
    "        f'Litter/waste on road = Sanitation. Pole with wires = Power (DISCOM).\\n\\n'\n",
    "        f'Respond with JSON: {{\"group\": \"<group>\", \"department\": \"<exact category name>\", '\n",
    "        f'\"confidence\": <0.0-1.0>, \"rationale\": \"<brief reason>\"}}'\n",
    "    )\n",
    "\n",
    "\n",
    "def _build_single_pass_prompt() -> str:\n",
    "    \"\"\"Prompt for single-pass vision model classification with JSON output.\"\"\"\n",
    "    categories_block = '\\n'.join(\n",
    "        f'- {cat}: {CATEGORY_DEFINITIONS[cat]}' for cat in CANONICAL_CATEGORIES\n",
    "    )\n",
    "    return (\n",
    "        f'You are a civic complaint classifier for Indian municipal authorities.\\n'\n",
    "        f'Look at the image and classify it into the SINGLE best matching category.\\n\\n'\n",
    "        f'Categories:\\n{categories_block}\\n\\n'\n",
    "        f'Decision rules:\\n'\n",
    "        f'1. Dangling wires, power cables, transformer â†’ Utility - Power (DISCOM)\\n'\n",
    "        f'2. Waterlogging, flood, drain overflow, sewer â†’ Municipal - Water & Sewerage\\n'\n",
    "        f'3. Garbage, trash, waste, dump, litter â†’ Municipal - Sanitation\\n'\n",
    "        f'4. Potholes, broken road, pavement damage â†’ Municipal - PWD (Roads)\\n'\n",
    "        f'5. Broken street lights, lamp posts â†’ Municipal - Street Lighting\\n'\n",
    "        f'6. Fallen trees, overgrown parks â†’ Municipal - Horticulture\\n'\n",
    "        f'7. Smoke, burning, industrial pollution â†’ Pollution Control Board\\n'\n",
    "        f'8. Illegal parking, encroachment â†’ Police - Local Law Enforcement\\n'\n",
    "        f'9. Traffic signal failure, road blockage â†’ Police - Traffic\\n'\n",
    "        f'10. Damaged bus shelter, state bus â†’ State Transport\\n'\n",
    "        f'11. Black/blurry/selfie/food â†’ Uncategorized\\n\\n'\n",
    "        f'Respond with JSON: {{\"department\": \"<exact category name>\", '\n",
    "        f'\"confidence\": <0.0-1.0>, \"rationale\": \"<brief reason>\"}}'\n",
    "    )\n",
    "\n",
    "\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# CLASSIFY FUNCTION â€” all fixes integrated\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "def classify(image_path: Path) -> dict:\n",
    "    \"\"\"\n",
    "    Classify a civic complaint image.\n",
    "    \n",
    "    Returns dict with:\n",
    "        department:         canonical category name\n",
    "        confidence:         model-reported confidence (0.0-1.0)\n",
    "        method:             'single_pass' | 'reasoning' | 'keyword_fallback' | 'error'\n",
    "        vision_description: free-text description from vision model (accuracy mode)\n",
    "        rationale:          model's reasoning for the classification\n",
    "        raw_json:           raw JSON string from the model\n",
    "        is_valid:           whether this is a valid civic complaint\n",
    "    \"\"\"\n",
    "    try:\n",
    "        image_bytes = load_as_jpeg_bytes(image_path)\n",
    "\n",
    "        # â”€â”€ FAST MODE: Single-pass vision classification â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "        if SINGLE_PASS:\n",
    "            resp = ollama.generate(\n",
    "                model=VISION_MODEL,\n",
    "                format='json',              # FIX: enforces JSON output\n",
    "                prompt=_build_single_pass_prompt(),\n",
    "                images=[image_bytes],\n",
    "                options={'num_ctx': 2048, 'temperature': 0.0},\n",
    "            )\n",
    "            raw_json = resp['response'].strip()\n",
    "            method = 'single_pass'\n",
    "            description = ''\n",
    "\n",
    "            try:\n",
    "                parsed = json.loads(raw_json)\n",
    "                raw_label = str(parsed.get('department', 'Uncategorized'))\n",
    "                confidence = float(parsed.get('confidence', 0.5))\n",
    "                rationale = str(parsed.get('rationale', ''))\n",
    "            except (json.JSONDecodeError, ValueError, TypeError):\n",
    "                raw_label = raw_json\n",
    "                confidence = 0.5\n",
    "                rationale = ''\n",
    "\n",
    "            canonical = canonicalize(raw_label)\n",
    "\n",
    "            # Keyword fallback on rationale text if Uncategorized\n",
    "            if canonical == 'Uncategorized':\n",
    "                kw_text = rationale + ' ' + raw_label\n",
    "                kw_result = keyword_fallback(kw_text)\n",
    "                if kw_result != 'Uncategorized':\n",
    "                    canonical = kw_result\n",
    "                    method = 'keyword_fallback'\n",
    "                    confidence = min(confidence, 0.65)\n",
    "\n",
    "            is_valid = canonical != 'Uncategorized'\n",
    "            return {\n",
    "                'department': canonical,\n",
    "                'confidence': confidence if is_valid else max(confidence * 0.5, 0.1),\n",
    "                'method': method,\n",
    "                'vision_description': description,\n",
    "                'rationale': rationale,\n",
    "                'raw_json': raw_json,\n",
    "                'is_valid': is_valid,\n",
    "            }\n",
    "\n",
    "        # â”€â”€ ACCURACY MODE: Two-step Visionâ†’Reasoning â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "        # Step 1 â€” Vision: Describe the image (free text)\n",
    "        vision_resp = ollama.generate(\n",
    "            model=VISION_MODEL,\n",
    "            prompt=(\n",
    "                'You are analyzing a civic complaint photo from India. '\n",
    "                'Describe what you see in 2-3 factual sentences. '\n",
    "                'Focus on: what is visibly damaged or problematic, '\n",
    "                'the setting (road, park, building, drain, etc.), '\n",
    "                'and any visible hazards or health/safety risks. '\n",
    "                'Be specific and objective. Do not greet or explain yourself.'\n",
    "            ),\n",
    "            images=[image_bytes],\n",
    "            options={'num_ctx': 2048, 'temperature': 0.2},\n",
    "        )\n",
    "        description = vision_resp['response'].strip()\n",
    "\n",
    "        # Step 2 â€” Reasoning: Hierarchical JSON classification\n",
    "        assert REASONING_MODEL is not None, 'REASONING_MODEL must be set in accuracy mode'\n",
    "        reasoning_resp = ollama.generate(\n",
    "            model=REASONING_MODEL,\n",
    "            format='json',                  # FIX: enforces JSON output\n",
    "            options={'num_ctx': 2048, 'temperature': 0.1},\n",
    "            prompt=_build_reasoning_prompt(description),\n",
    "        )\n",
    "        raw_json = reasoning_resp['response'].strip()\n",
    "        method = 'reasoning'\n",
    "\n",
    "        # Parse structured JSON\n",
    "        try:\n",
    "            parsed = json.loads(raw_json)\n",
    "            raw_label = str(parsed.get('department', 'Uncategorized'))\n",
    "            confidence = float(parsed.get('confidence', 0.5))\n",
    "            rationale = str(parsed.get('rationale', ''))\n",
    "        except (json.JSONDecodeError, ValueError, TypeError):\n",
    "            raw_label = raw_json\n",
    "            confidence = 0.5\n",
    "            rationale = ''\n",
    "\n",
    "        canonical = canonicalize(raw_label)\n",
    "\n",
    "        # Keyword fallback if reasoning returned Uncategorized\n",
    "        if canonical == 'Uncategorized':\n",
    "            kw_result = keyword_fallback(description)\n",
    "            if kw_result != 'Uncategorized':\n",
    "                canonical = kw_result\n",
    "                method = 'keyword_fallback'\n",
    "                confidence = min(confidence, 0.65)\n",
    "\n",
    "        # Check if image is non-civic\n",
    "        desc_lower = description.lower()\n",
    "        is_non_civic = any(kw in desc_lower for kw in _NEGATIVE_KEYWORDS)\n",
    "        is_valid = (canonical != 'Uncategorized') and not is_non_civic\n",
    "\n",
    "        return {\n",
    "            'department': canonical,\n",
    "            'confidence': confidence if is_valid else max(confidence * 0.5, 0.1),\n",
    "            'method': method,\n",
    "            'vision_description': description,\n",
    "            'rationale': rationale,\n",
    "            'raw_json': raw_json,\n",
    "            'is_valid': is_valid,\n",
    "        }\n",
    "\n",
    "    except Exception as e:\n",
    "        return {\n",
    "            'department': 'Uncategorized',\n",
    "            'confidence': 0.0,\n",
    "            'method': 'error',\n",
    "            'vision_description': f'ERROR: {e}',\n",
    "            'rationale': '',\n",
    "            'raw_json': '',\n",
    "            'is_valid': False,\n",
    "        }\n",
    "\n",
    "print(f'âœ… Classifier ready (mode={MODE}, json_output=True, keyword_fallback=True, hierarchical=True)')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1cbcf24",
   "metadata": {},
   "source": [
    "## 4 â€” Run re-sort (with full audit trail)\n",
    "\n",
    "Reads images from the Kaggle input datasets and writes sorted copies to `/kaggle/working/ai_sorted_dataset/`.\n",
    "\n",
    "> **Note:** Kaggle input datasets are read-only, so images are **copied** (not moved).\n",
    "\n",
    "### Audit columns in the CSV\n",
    "| Column | Description |\n",
    "|--------|-------------|\n",
    "| `method` | `reasoning`, `single_pass`, `keyword_fallback`, or `error` |\n",
    "| `confidence` | Model-reported confidence 0.0â€“1.0 |\n",
    "| `rationale` | Model's reasoning for classification |\n",
    "| `raw_json` | Complete raw JSON from the model |\n",
    "| `vision_description` | Free-text image description (accuracy mode) |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d6b5d77",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import random\n",
    "import shutil\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "# â”€â”€ Controls â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "SAMPLE_PER_FOLDER = 5    # 0 = process all; >0 = sample N per folder for testing\n",
    "RESUME = True\n",
    "MAX_IMAGES_PER_RUN = 0   # 0 = process all remaining\n",
    "\n",
    "random.seed(42)\n",
    "\n",
    "# â”€â”€ Collect images â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "def collect_images(sources: list, sample: int) -> list:\n",
    "    images = []\n",
    "    for source in sources:\n",
    "        for folder in sorted(source.iterdir()):\n",
    "            if not folder.is_dir():\n",
    "                continue\n",
    "            found = [p for p in folder.iterdir() if p.suffix.lower() in IMAGE_EXTS]\n",
    "            if not found:\n",
    "                continue\n",
    "            picked = random.sample(found, min(sample, len(found))) if sample else found\n",
    "            images.extend(picked)\n",
    "    return images\n",
    "\n",
    "def safe_copy(src: Path, dest_dir: Path) -> Path:\n",
    "    dest_dir.mkdir(parents=True, exist_ok=True)\n",
    "    dest = dest_dir / src.name\n",
    "    if dest.exists():\n",
    "        counter = 1\n",
    "        while dest.exists():\n",
    "            dest = dest_dir / f'{src.stem}_{counter}{src.suffix}'\n",
    "            counter += 1\n",
    "    shutil.copy2(src, dest)\n",
    "    return dest\n",
    "\n",
    "# â”€â”€ Resume support â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "processed = set()\n",
    "if RESUME and REPORT_CSV.exists():\n",
    "    with open(REPORT_CSV, 'r', newline='', encoding='utf-8') as f:\n",
    "        reader = csv.DictReader(f)\n",
    "        for row in reader:\n",
    "            src = row.get('source_path')\n",
    "            if src:\n",
    "                processed.add(src)\n",
    "    print(f'Resume enabled: {len(processed)} already processed')\n",
    "\n",
    "images = collect_images(INPUT_ROOTS, SAMPLE_PER_FOLDER)\n",
    "print(f'Total images to process: {len(images)}')\n",
    "\n",
    "OUTPUT_ROOT.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# â”€â”€ Expanded CSV headers (full audit trail) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "headers = [\n",
    "    'filename', 'source_path', 'source_folder', 'original_label',\n",
    "    'ai_label', 'confidence', 'method', 'rationale',\n",
    "    'vision_description', 'raw_json', 'is_valid', 'dest_path',\n",
    "]\n",
    "\n",
    "FOLDER_TO_LABEL = {\n",
    "    'Municipal_-_PWD_Roads':          'Municipal - PWD (Roads)',\n",
    "    'Municipal_-_Sanitation':         'Municipal - Sanitation',\n",
    "    'Municipal_-_Horticulture':       'Municipal - Horticulture',\n",
    "    'Municipal_-_Street_Lighting':    'Municipal - Street Lighting',\n",
    "    'Municipal_-_Water_and_Sewerage': 'Municipal - Water & Sewerage',\n",
    "    'Utility_-_Power_DISCOM':         'Utility - Power (DISCOM)',\n",
    "    'State_Transport':                'State Transport',\n",
    "    'Pollution_Control_Board':        'Pollution Control Board',\n",
    "    'Police_-_Local_Law_Enforcement': 'Police - Local Law Enforcement',\n",
    "    'Police_-_Traffic':               'Police - Traffic',\n",
    "    'Uncategorized':                  'Uncategorized',\n",
    "}\n",
    "\n",
    "# â”€â”€ Stats â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "moved = same = errors = skipped = processed_this_run = 0\n",
    "method_counts = {}  # track how each classification method is used\n",
    "\n",
    "file_mode = 'a' if RESUME and REPORT_CSV.exists() and REPORT_CSV.stat().st_size > 0 else 'w'\n",
    "write_header = file_mode == 'w'\n",
    "\n",
    "# â”€â”€ Main classification loop â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "with open(REPORT_CSV, file_mode, newline='', encoding='utf-8') as f:\n",
    "    writer = csv.DictWriter(f, fieldnames=headers)\n",
    "    if write_header:\n",
    "        writer.writeheader()\n",
    "\n",
    "    for img_path in tqdm(images, desc='Re-sorting', unit='img'):\n",
    "        if RESUME and str(img_path) in processed:\n",
    "            skipped += 1\n",
    "            continue\n",
    "\n",
    "        folder_name = img_path.parent.name\n",
    "        original_label = FOLDER_TO_LABEL.get(folder_name, folder_name.replace('_', ' '))\n",
    "\n",
    "        try:\n",
    "            result = classify(img_path)\n",
    "            ai_label    = result['department']\n",
    "            confidence  = result['confidence']\n",
    "            method      = result['method']\n",
    "            rationale   = result.get('rationale', '')\n",
    "            vision_desc = result.get('vision_description', '')\n",
    "            raw_json    = result.get('raw_json', '')\n",
    "            is_valid    = result.get('is_valid', True)\n",
    "\n",
    "            if confidence <= 0.1 or ai_label in ('Unknown', ''):\n",
    "                ai_label = 'Uncategorized'\n",
    "\n",
    "            dest_dir = OUTPUT_ROOT / safe_dirname(ai_label)\n",
    "            dest_path = safe_copy(img_path, dest_dir)\n",
    "\n",
    "            if ai_label != original_label:\n",
    "                moved += 1\n",
    "            else:\n",
    "                same += 1\n",
    "\n",
    "            method_counts[method] = method_counts.get(method, 0) + 1\n",
    "\n",
    "        except Exception as e:\n",
    "            errors += 1\n",
    "            ai_label = 'Uncategorized'\n",
    "            confidence = 0.0\n",
    "            method = 'error'\n",
    "            rationale = ''\n",
    "            vision_desc = f'ERROR: {e}'\n",
    "            raw_json = ''\n",
    "            is_valid = False\n",
    "            dest_path = ''\n",
    "\n",
    "        writer.writerow({\n",
    "            'filename':           img_path.name,\n",
    "            'source_path':        str(img_path),\n",
    "            'source_folder':      folder_name,\n",
    "            'original_label':     original_label,\n",
    "            'ai_label':           ai_label,\n",
    "            'confidence':         f'{confidence:.3f}',\n",
    "            'method':             method,\n",
    "            'rationale':          rationale[:200],  # truncate for CSV readability\n",
    "            'vision_description': vision_desc[:300],\n",
    "            'raw_json':           raw_json[:500],\n",
    "            'is_valid':           is_valid,\n",
    "            'dest_path':          str(dest_path),\n",
    "        })\n",
    "        processed_this_run += 1\n",
    "\n",
    "        if MAX_IMAGES_PER_RUN and processed_this_run >= MAX_IMAGES_PER_RUN:\n",
    "            break\n",
    "\n",
    "print(f'\\nâœ… Done!')\n",
    "print(f'   Processed this run : {processed_this_run}')\n",
    "print(f'   Skipped (resume)   : {skipped}')\n",
    "if processed_this_run:\n",
    "    print(f'   Re-labelled        : {moved}  ({moved/processed_this_run*100:.1f}%)')\n",
    "    print(f'   Confirmed          : {same}  ({same/processed_this_run*100:.1f}%)')\n",
    "print(f'   Errors             : {errors}')\n",
    "print(f'   Report CSV         : {REPORT_CSV}')\n",
    "print(f'\\n   Methods used:')\n",
    "for m, c in sorted(method_counts.items(), key=lambda x: -x[1]):\n",
    "    print(f'     {m:<25} {c:>5}  ({c/processed_this_run*100:.1f}%)') if processed_this_run else None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9cf8903",
   "metadata": {},
   "source": [
    "## 5 â€” Output summary & explainability analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da037aef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(REPORT_CSV)\n",
    "\n",
    "print('=' * 60)\n",
    "print('  CLASSIFICATION REPORT')\n",
    "print('=' * 60)\n",
    "\n",
    "print('\\nğŸ“Š Per-category output counts:')\n",
    "print(df['ai_label'].value_counts().to_string())\n",
    "\n",
    "print('\\nğŸ”§ Classification method breakdown:')\n",
    "method_stats = df['method'].value_counts()\n",
    "for m, c in method_stats.items():\n",
    "    print(f'  {m:<25} {c:>5}  ({c/len(df)*100:.1f}%)')\n",
    "\n",
    "print(f'\\nğŸ“ˆ Confidence statistics:')\n",
    "df['confidence'] = pd.to_numeric(df['confidence'], errors='coerce')\n",
    "print(f'  Mean confidence  : {df[\"confidence\"].mean():.3f}')\n",
    "print(f'  Median confidence: {df[\"confidence\"].median():.3f}')\n",
    "print(f'  Min confidence   : {df[\"confidence\"].min():.3f}')\n",
    "print(f'  Max confidence   : {df[\"confidence\"].max():.3f}')\n",
    "\n",
    "# Confidence distribution by method\n",
    "print(f'\\n  Confidence by method:')\n",
    "for method in df['method'].unique():\n",
    "    subset = df[df['method'] == method]['confidence']\n",
    "    print(f'    {method:<25} mean={subset.mean():.3f}  median={subset.median():.3f}')\n",
    "\n",
    "print('\\nğŸ”€ Re-labelled from â†’ to (top 20):')\n",
    "relabelled = df[df['original_label'] != df['ai_label']]\n",
    "if not relabelled.empty:\n",
    "    print(relabelled.groupby(['original_label', 'ai_label']).size()\n",
    "          .sort_values(ascending=False).head(20).to_string())\n",
    "else:\n",
    "    print('  (none re-labelled)')\n",
    "\n",
    "# Uncategorized analysis\n",
    "uncat = df[df['ai_label'] == 'Uncategorized']\n",
    "print(f'\\nâš ï¸  Uncategorized: {len(uncat)} / {len(df)} ({len(uncat)/len(df)*100:.1f}%)')\n",
    "if not uncat.empty:\n",
    "    print(f'  Original labels of uncategorized images:')\n",
    "    print(uncat['original_label'].value_counts().head(10).to_string())\n",
    "\n",
    "# Keyword fallback analysis\n",
    "kw_fallback = df[df['method'] == 'keyword_fallback']\n",
    "if not kw_fallback.empty:\n",
    "    print(f'\\nğŸ”‘ Keyword fallback rescued {len(kw_fallback)} images:')\n",
    "    print(kw_fallback['ai_label'].value_counts().to_string())\n",
    "\n",
    "print('\\nğŸ“ Output folder sizes:')\n",
    "for cat_dir in sorted(OUTPUT_ROOT.iterdir()):\n",
    "    if cat_dir.is_dir():\n",
    "        n = sum(1 for _ in cat_dir.iterdir())\n",
    "        print(f'  {cat_dir.name:<45} {n:>5}')\n",
    "\n",
    "print(f'\\nğŸ“„ Full report: {REPORT_CSV}')"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
